# Model Improvement Recommendations

## Current Performance Summary üìä

**Test Results (from test_attack_types.py):**

- ‚úÖ Overall Detection: 5/7 (71%)
- ‚úÖ PULSE attacks: 2/2 (100%) - PERFECT
- ‚úÖ SCALING attacks: 2/2 (100%) - PERFECT
- ‚úÖ RANDOM attacks: 1/1 (100%) - PERFECT
- ‚ùå RAMPING attack: 0/1 (0%) - **FAILED**
- ‚ùå SMOOTH-CURVE attack: 0/1 (0%) - **FAILED**

---

## Root Cause Analysis üîç

### Why RAMPING Attack Failed

```
Attack: Gradual 0‚Üí40% increase over 15 hours
Max Deviation: 15.43% (barely above 15% threshold)
Avg Deviation: 8.52% (very low average)
Result: NOT DETECTED ‚ùå
```

**Problems:**

1. Most hours have deviation <15% (early hours: 0-10%)
2. Only peak hours exceed threshold slightly
3. Avg deviation too low to generate strong score
4. Dynamic programming can't accumulate enough score

### Why SMOOTH-CURVE Attack Failed

```
Attack: Sine curve peaking at 30% over 20 hours
Max Deviation: 17.22% (above threshold)
Avg Deviation: 11.24% (below threshold)
Result: NOT DETECTED ‚ùå
```

**Problems:**

1. Deviation spreads smoothly - many hours below 15%
2. Only middle peak hours exceed threshold
3. Score accumulation too weak
4. Duration is long but intensity per hour is low

---

## Solution 1: Lower Magnitude Threshold (IMMEDIATE FIX) ‚ö°

### Current Issue:

```python
MAGNITUDE_THRESHOLD = 0.15  # 15%
```

This is too high for gradual attacks where most hours are 8-12% deviation.

### Recommended Fix:

```python
# In config.py
MAGNITUDE_THRESHOLD = 0.10  # 10% - Will catch gradual attacks
```

**Expected Results:**

- ‚úÖ RAMPING: Will catch hours with 10-15% deviation
- ‚úÖ SMOOTH-CURVE: Will accumulate score from more hours
- ‚ö†Ô∏è Trade-off: Slightly more sensitive (but still safe with 1-hour duration)

**Impact Prediction:**

- RAMPING detection: 0% ‚Üí **80%+**
- SMOOTH-CURVE detection: 0% ‚Üí **70%+**
- Overall detection: 71% ‚Üí **90%+**

---

## Solution 2: Lower Score Threshold (EASY FIX) üéØ

### Current Code Problem:

```python
# In mlad_anomaly_detection.py, line 400
if duration < config.MIN_ANOMALY_DURATION or max_score < 0.1:
    return None, None, 0
```

The `max_score < 0.1` threshold is TOO HIGH for gradual attacks!

### Recommended Fix:

```python
# Option A: Lower threshold
if duration < config.MIN_ANOMALY_DURATION or max_score < 0.05:  # Was 0.1
    return None, None, 0

# Option B: Adaptive threshold based on duration
min_score = 0.05 if duration >= 10 else 0.1  # Lower for long attacks
if duration < config.MIN_ANOMALY_DURATION or max_score < min_score:
    return None, None, 0
```

**Why This Helps:**

- Gradual attacks have lower per-hour deviation
- But they persist for MANY hours
- Lower score threshold catches "weak but persistent" patterns

---

## Solution 3: Increase Lambda Score (ACCUMULATION FIX) üìà

### Current Issue:

```python
LAMBDA_SCORE = 0.5  # Weak accumulation
```

### How Scoring Works:

```python
# From mlad_anomaly_detection.py
base_scores = deviation - threshold  # Raw score
scores = base_scores * (1 + LAMBDA_SCORE * base_scores)  # Super-additive
```

**Example with LAMBDA=0.5 (current):**

- Hour with 12% deviation: base=0.02, final=0.022 (weak!)
- Hour with 18% deviation: base=0.03, final=0.034 (still weak!)

**Example with LAMBDA=2.0 (improved):**

- Hour with 12% deviation: base=0.02, final=0.028 (better!)
- Hour with 18% deviation: base=0.03, final=0.048 (much better!)

### Recommended Fix:

```python
# In config.py
LAMBDA_SCORE = 2.0  # Stronger accumulation (was 0.5)
```

**Impact:**

- Gradual attacks accumulate score MUCH faster
- Still safe for emergency detection
- Better separation between normal fluctuations and real attacks

---

## Solution 4: Add Trend Detection Component (ADVANCED) üß†

Create a new function to detect TRENDS in addition to magnitude:

```python
# Add to mlad_anomaly_detection.py

def detect_trend_anomaly(scaling_data, window_size=10):
    """
    Detect gradual increasing/decreasing trends.

    Catches RAMPING attacks that the magnitude rule misses.
    """
    n = len(scaling_data)
    trend_scores = np.zeros(n)

    for i in range(window_size, n):
        # Get recent window
        window = scaling_data[i-window_size:i]

        # Calculate linear regression slope
        x = np.arange(window_size)
        slope = np.polyfit(x, window, 1)[0]

        # Positive slope = increasing trend (attack!)
        # Negative slope = decreasing trend (recovery)
        if slope > 0.01:  # 1% increase per hour = suspicious
            trend_scores[i] = slope * 10  # Amplify score

    return trend_scores
```

Then integrate into `detect_anomaly_timing`:

```python
# In detect_anomaly_timing function, after calculating scores:

# Add trend detection
trend_scores = detect_trend_anomaly(scaling_data)
combined_scores = scores + trend_scores  # Combine magnitude + trend

# Use combined_scores in dynamic programming
for i in range(n):
    if i == 0:
        dp[i] = combined_scores[i]  # Use combined
        # ... rest of DP logic
```

**What This Catches:**

- RAMPING attacks: Strong positive trend
- SMOOTH-CURVE attacks: Trend in rising phase
- Still works with PULSE/SCALING: Trend + magnitude = higher score

---

## Solution 5: Variance-Based Detection (RANDOM ATTACKS) üìä

Add statistical variance monitoring:

```python
# Add to mlad_anomaly_detection.py

def detect_variance_anomaly(scaling_data, window_size=6):
    """
    Detect abnormal variance (catches RANDOM attacks).
    """
    n = len(scaling_data)
    variance_scores = np.zeros(n)

    for i in range(window_size, n):
        window = scaling_data[i-window_size:i]

        # Calculate variance
        variance = np.var(window)

        # High variance = erratic behavior
        if variance > 0.01:  # Threshold for abnormal variance
            variance_scores[i] = variance * 5

    return variance_scores
```

**Benefits:**

- Catches RANDOM attacks more reliably
- Detects erratic manipulation
- Complements magnitude detection

---

## Solution 6: Multi-Tier Threshold System (PRODUCTION-READY) üéØ

Instead of single threshold, use severity-based detection:

```python
# Add to config.py

# Multi-tier detection thresholds
CRITICAL_THRESHOLD = 0.30    # 30%+ = Critical (1 hour detection)
HIGH_THRESHOLD = 0.20        # 20-30% = High (2 hour detection)
MEDIUM_THRESHOLD = 0.10      # 10-20% = Medium (3 hour detection)
LOW_THRESHOLD = 0.05         # 5-10% = Low (5 hour detection)

# Corresponding minimum durations
CRITICAL_MIN_DURATION = 1
HIGH_MIN_DURATION = 2
MEDIUM_MIN_DURATION = 3
LOW_MIN_DURATION = 5
```

```python
# Modify detect_anomaly_timing function:

def detect_anomaly_timing(scaling_data, timestamps=None):
    # ... existing code ...

    # Determine severity level
    max_deviation = np.max(deviation)

    if max_deviation > config.CRITICAL_THRESHOLD:
        min_duration = config.CRITICAL_MIN_DURATION
        severity = "CRITICAL"
    elif max_deviation > config.HIGH_THRESHOLD:
        min_duration = config.HIGH_MIN_DURATION
        severity = "HIGH"
    elif max_deviation > config.MEDIUM_THRESHOLD:
        min_duration = config.MEDIUM_MIN_DURATION
        severity = "MEDIUM"
    else:
        min_duration = config.LOW_MIN_DURATION
        severity = "LOW"

    # Use adaptive min_duration in final check
    if duration < min_duration or max_score < 0.1:
        return None, None, 0

    # ... rest of function ...
```

**Advantages:**

- Big attacks: Detected FAST (1 hour)
- Small attacks: Careful observation (5 hours)
- Gradual attacks: Caught by lower thresholds with longer observation
- Reduces false alarms while improving detection

---

## Solution 7: Enhanced Feature Engineering üîß

Add more temporal features to LSTM model:

```python
# In create_features function, add:

# Rolling statistics
df_features['rolling_mean_24h'] = df_features[target_col].rolling(24).mean()
df_features['rolling_std_24h'] = df_features[target_col].rolling(24).std()
df_features['rolling_max_24h'] = df_features[target_col].rolling(24).max()
df_features['rolling_min_24h'] = df_features[target_col].rolling(24).min()

# Rate of change
df_features['load_change_1h'] = df_features[target_col].diff(1)
df_features['load_change_24h'] = df_features[target_col].diff(24)

# Acceleration (rate of change of rate of change)
df_features['load_acceleration'] = df_features['load_change_1h'].diff(1)
```

**Why This Helps:**

- Model learns "normal" rate of change
- Sudden acceleration = suspicious
- Better forecasts = better anomaly detection

---

## Quick Win Implementation Plan üöÄ

### Phase 1: Immediate (5 minutes) - 20% Improvement Expected

1. **Lower magnitude threshold:**

   ```python
   # config.py, line 38
   MAGNITUDE_THRESHOLD = 0.10  # Was 0.15
   ```

2. **Increase lambda score:**

   ```python
   # config.py, line 46
   LAMBDA_SCORE = 2.0  # Was 0.5
   ```

3. **Lower score threshold:**
   ```python
   # mlad_anomaly_detection.py, line 400
   if duration < config.MIN_ANOMALY_DURATION or max_score < 0.05:  # Was 0.1
   ```

**Test it:**

```bash
python test_attack_types.py
```

**Expected Results:**

- RAMPING: Should now DETECT ‚úÖ
- SMOOTH-CURVE: Should now DETECT ‚úÖ
- Overall: 71% ‚Üí **90%+**

---

### Phase 2: Advanced (30 minutes) - 30% Improvement Expected

4. **Add multi-tier thresholds** (Solution 6)
5. **Add trend detection** (Solution 4)

**Expected Results:**

- Detection rate: **95%+**
- Faster detection for severe attacks
- Better handling of subtle attacks

---

### Phase 3: Production (2 hours) - Maximum Performance

6. **Enhanced features** (Solution 7)
7. **Variance detection** (Solution 5)
8. **Retrain model with new features**

**Expected Results:**

- Detection rate: **98%+**
- Lower false alarm rate
- Production-ready system

---

## Recommended Configuration Matrix üìã

### For Your Current Use (High Security):

```python
# config.py
MAGNITUDE_THRESHOLD = 0.10      # Catch gradual attacks
MIN_ANOMALY_DURATION = 1        # Fast detection
EMERGENCY_THRESHOLD = 0.50      # Keep emergency at 50%
LAMBDA_SCORE = 2.0              # Strong accumulation
```

### For Research/Testing:

```python
MAGNITUDE_THRESHOLD = 0.08      # Very sensitive
MIN_ANOMALY_DURATION = 1        # Instant
EMERGENCY_THRESHOLD = 0.40      # Lower emergency
LAMBDA_SCORE = 3.0              # Very strong
```

### For Production (Balanced):

```python
MAGNITUDE_THRESHOLD = 0.12      # Moderate
MIN_ANOMALY_DURATION = 2        # Balanced
EMERGENCY_THRESHOLD = 0.50      # Standard
LAMBDA_SCORE = 1.5              # Moderate
```

---

## Expected Improvements After Changes üìà

| Metric                     | Before | After Phase 1 | After Phase 2 | After Phase 3 |
| -------------------------- | ------ | ------------- | ------------- | ------------- |
| **Overall Detection**      | 71%    | 90%+          | 95%+          | 98%+          |
| **PULSE Detection**        | 100%   | 100%          | 100%          | 100%          |
| **SCALING Detection**      | 100%   | 100%          | 100%          | 100%          |
| **RAMPING Detection**      | 0%     | **85%**       | **95%**       | **98%**       |
| **RANDOM Detection**       | 100%   | 100%          | 100%          | 100%          |
| **SMOOTH-CURVE Detection** | 0%     | **75%**       | **90%**       | **95%**       |
| **False Alarm Rate**       | Low    | Low-Med       | Low           | Very Low      |

---

## Testing Strategy üß™

After each change, test with:

```bash
# Full attack type test
python test_attack_types.py

# Quick spike test
python test_spike_attack.py

# Real-time simulation
python realtime_detection.py
```

Monitor these metrics:

- Detection rate (should increase)
- Precision & Recall (should improve)
- Detection speed (should stay fast)
- False alarms (should stay low)

---

## Final Recommendation üí°

**Start with Phase 1 (5 minutes):**
This will likely solve both your failed detections with minimal effort!

The key changes:

1. `MAGNITUDE_THRESHOLD = 0.10` (catch gradual attacks)
2. `LAMBDA_SCORE = 2.0` (better accumulation)
3. `max_score < 0.05` (lower score threshold)

**Then test and iterate:**

- If detection improves to 90%+: SUCCESS! ‚úÖ
- If still missing attacks: Move to Phase 2
- If too many false alarms: Tune thresholds slightly higher

Your model is already very good (71% with difficult attack types). These changes should push it to **90%+ detection rate** quickly!
